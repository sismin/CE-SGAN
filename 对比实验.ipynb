{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE,BorderlineSMOTE\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = 8\n",
    "num_classes = 9\n",
    "latent_dim = 4\n",
    "shape = (8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##数据处理部分\n",
    "#用train_data  做训练集， 用blind_data盲井做验证集\n",
    "filename = './Dataset/美国油田/all_data不含PE缺失.xlsx'\n",
    "data=pd.read_excel(filename)\n",
    "data['Formation'] = pd.Categorical(data['Formation'])\n",
    "data['Formation'] = data.Formation.cat.codes\n",
    "train_data = data[~data['Well Name'].str.contains('STUART|CRAWFORD')]\n",
    "test_data = data[data['Well Name'].str.contains('STUART|CRAWFORD')]\n",
    "data_x = train_data.drop(['Well Name','Depth','Facies'],axis=1)\n",
    "data_x = data_x.values\n",
    "data_y = train_data['Facies']-1\n",
    "y_train = data_y.values\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "#标准化\n",
    "max_min = preprocessing.StandardScaler()\n",
    "X_train = max_min.fit_transform(data_x)\n",
    "# X_train = np.expand_dims(data_x,2)\n",
    "#验证集\n",
    "X_eval = test_data.drop(['Well Name','Depth','Facies'],axis=1)\n",
    "y_eval = test_data['Facies']-1\n",
    "y_eval = y_eval.values\n",
    "# y_eval = tf.keras.utils.to_categorical(y_eval, num_classes=num_classes)\n",
    "#标准化\n",
    "X_eval = X_eval.values\n",
    "X_eval = max_min.fit_transform(X_eval)\n",
    "X_eval = np.expand_dims(X_eval,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#数据分割 80%\n",
    "X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(X_train,y_train,test_size=0.2,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#数据分割 60%\n",
    "X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(X_train,y_train,test_size=0.4,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6642, 8), (6642,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=123456)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "X_resampled.shape , y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3987, 8), (3987,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=123456)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_, y_train_)\n",
    "X_resampled.shape , y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_resampled,y_resampled = SMOTE().fit_resample(X_train_, y_train_)\n",
    "X_resampled.shape , y_resampled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5310, 8), (5310,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled,y_resampled = BorderlineSMOTE().fit_resample(X_train_, y_train_)\n",
    "X_resampled.shape , y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Classifier():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Conv1D(filters = 256,kernel_size = 3, padding = 'same', activation='relu',input_shape=shape))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.MaxPooling1D(2,2))\n",
    "  model.add(layers.Conv1D(filters = 128,kernel_size = 3, padding = 'same', activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.MaxPooling1D(2,2))\n",
    "  model.add(layers.Conv1D(filters = 64,kernel_size = 3, padding = 'same', activation='relu'))\n",
    "  model.add(layers.MaxPooling1D(2,2))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1500,activation='relu'))\n",
    "  model.add(layers.Dense(500,activation='relu'))\n",
    "  model.add(layers.Dense(100,activation='relu'))\n",
    "  model.add(layers.Dense(num_classes,activation='softmax'))\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(X_train,y_train,test_size=0.8,stratify=y_train)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train_, y_train_)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=100,batch_size=256,validation_data=(X_eval, y_eval),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=123456)\n",
    "smo = SMOTE(random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(X_train,y_train,test_size=0.8,stratify=y_train)\n",
    "    X_resampled, y_resampled = smo.fit_resample(X_train_, y_train_)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=100,batch_size=256,validation_data=(X_eval, y_eval),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_resampled = np.expand_dims(X_resampled,2)\n",
    "model = Classifier()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "history = model.fit(X_resampled,y_resampled,epochs=100,batch_size=256,validation_data=(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=123456)\n",
    "smo = SMOTE(random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'E:/数据集/DGF-HGF.xlsx'\n",
    "DGF_data = pd.read_excel(filename,sheet_name='DGF data')\n",
    "HGF_data = pd.read_excel(filename,sheet_name='HGF data')\n",
    "dist_DGF = {'FS':0, 'MS':1, 'CS':2, 'PS':3, 'CR':4, 'S':5, 'M':6, 'C':7}\n",
    "dist = {'FS':0, 'MS':1, 'CS':2, 'PS':3, 'CR':4, 'S':5, 'M':6, 'C':7}\n",
    "all_data = pd.concat([DGF_data,HGF_data])\n",
    "all_data['Face'] = all_data['Type'].map(dist)\n",
    "x_data = pd.DataFrame(all_data,columns=['GR','AC','DEN','CNL','LLD','LLS','CAL'])\n",
    "y_data = pd.DataFrame(all_data,columns=['Face'])\n",
    "x_data = x_data.values\n",
    "y_data = y_data.values\n",
    "max_min = preprocessing.StandardScaler()\n",
    "x_data = max_min.fit_transform(x_data)\n",
    "all_data_ = np.concatenate((x_data,y_data.reshape(-1,1)),axis=1)\n",
    "np.random.shuffle(all_data_)\n",
    "x_data_ = all_data_[:,:-1]\n",
    "y_data_ = all_data_[:,-1]\n",
    "x_data_ = np.expand_dims(x_data_,2)\n",
    "# y_data_ = np.expand_dims(y_data_,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#8 2 分割训练和验证 \n",
    "train_x,val_x,train_y,val_y=model_selection.train_test_split(x_data_,y_data_,test_size=0.2,stratify=y_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Classifier():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Conv1D(filters = 64,kernel_size = 3, padding = 'same',input_shape=(7,1)))  \n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Activation('relu'))\n",
    "  model.add(layers.MaxPooling1D(2,1))\n",
    "  model.add(layers.Conv1D(filters = 128,kernel_size = 3, padding = 'same'))  \n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Activation('relu'))\n",
    "  model.add(layers.MaxPooling1D(2,1))\n",
    "  model.add(layers.Conv1D(filters = 128,kernel_size = 3, padding = 'same'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Activation('relu'))\n",
    "  model.add(layers.MaxPooling1D(2,1))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1500))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Activation('relu'))\n",
    "  model.add(layers.Dense(500))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Activation('relu'))\n",
    "  model.add(layers.Dense(8,activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1722, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x  = train_x.reshape(-1,7)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_resampled, y_resampled = ros.fit_resample(train_x, train_y)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=200,batch_size=256,validation_data=(val_x, val_y),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_resampled, y_resampled = smo.fit_resample(train_x, train_y)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=200,batch_size=256,validation_data=(val_x, val_y),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(train_x,train_y,test_size=0.2,stratify=train_y)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train_, y_train_)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=200,batch_size=256,validation_data=(val_x, val_y),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(train_x,train_y,test_size=0.2,stratify=train_y)\n",
    "    X_resampled, y_resampled = smo.fit_resample(X_train_, y_train_)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=200,batch_size=256,validation_data=(val_x, val_y),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(train_x,train_y,test_size=0.4,stratify=train_y)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train_, y_train_)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=200,batch_size=256,validation_data=(val_x, val_y),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(train_x,train_y,test_size=0.4,stratify=train_y)\n",
    "    X_resampled, y_resampled = smo.fit_resample(X_train_, y_train_)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=200,batch_size=256,validation_data=(val_x, val_y),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(train_x,train_y,test_size=0.6,stratify=train_y)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train_, y_train_)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=200,batch_size=256,validation_data=(val_x, val_y),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_,X_test_,y_train_,y_test_ = model_selection.train_test_split(train_x,train_y,test_size=0.6,stratify=train_y)\n",
    "    X_resampled, y_resampled = smo.fit_resample(X_train_, y_train_)\n",
    "    X_resampled = np.expand_dims(X_resampled,2)\n",
    "    model = Classifier()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "    history = model.fit(X_resampled,y_resampled,epochs=200,batch_size=256,validation_data=(val_x, val_y),verbose=0)\n",
    "    print(max(history.history['val_accuracy']))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}